---
layout: post
title: "Numba를 이용한 Cuda 프로그램 예제"
comments: true
share: true
date: 2019-07-07 12:58:00
description: Python에서 Numba를 이용한 Cuda 프로그래밍 예제를 소개한다.
tags: python cuda
sitemap :
  changefreq : daily
  priority : 1.0
---

# Numba를 이용한 Cuda 프로그램 예제

## 1. 시간 측정 함수


```python
class Timer:
    """클래스 생성 시점부터 소멸 시점까지의 시간을 출력한다."""

    def __init__(self, func_name: str='this func'):
        self.func_name: str = func_name
        self.time_start: float = 0.0

    def __enter__(self):
        import sys
        import time
        print('{} ==>'.format(self.func_name), end=' ')
        sys.stdout.flush()
        self.time_start = time.process_time()
        return self

    def __exit__(self, *args):
        import time
        time_end = time.process_time()
        interval = time_end - self.time_start
        print('Elapsed time: {:.8f} sec'.format(interval))
```

<br>

## 2. Device Info [1]


```python
import pycuda.driver as drv
drv.init()

print('Detected {} CUDA Capable device(s) \n'.format(drv.Device.count()))

for i in range(drv.Device.count()):

    dev = drv.Device(i)
    print(f'Device {i}: {dev.name()}')
    compute_capability = float('%d.%d' % dev.compute_capability())
    print(f'  Compute Capability: {compute_capability}')
    print(f'  Total Memory: {dev.total_memory() // (1024**2)} MB')

    dev_attr_tuples = dev.get_attributes().items()
    dev_attributes = {}

    for k, v in dev_attr_tuples:
        dev_attributes[str(k)] = v

    num_mp = dev_attributes['MULTIPROCESSOR_COUNT']

    cuda_cores_per_mp = {5.0 : 128,
                         5.1 : 128,
                         5.2 : 128,
                         6.0 : 64,
                         6.1 : 128,
                         6.2 : 128}[compute_capability]
    print(f'  Multiprocessors: {num_mp}')
    print(f'  CUDA Cores Per Multiprocessor: {cuda_cores_per_mp}')
    print(f'  Total CUDA Cores: {num_mp * cuda_cores_per_mp}')

    dev_attributes.pop('MULTIPROCESSOR_COUNT')

    for k in dev_attributes.keys():
        print(f'  {k}: {dev_attributes[k]}')

```

    Detected 1 CUDA Capable device(s) 
    
    Device 0: GeForce GTX 850M
      Compute Capability: 5.0
      Total Memory: 2004 MB
      Multiprocessors: 5
      CUDA Cores Per Multiprocessor: 128
      Total CUDA Cores: 640
      ASYNC_ENGINE_COUNT: 1
      CAN_MAP_HOST_MEMORY: 1
      CLOCK_RATE: 901500
      COMPUTE_CAPABILITY_MAJOR: 5
      COMPUTE_CAPABILITY_MINOR: 0
      COMPUTE_MODE: DEFAULT
      CONCURRENT_KERNELS: 1
      ECC_ENABLED: 0
      GLOBAL_L1_CACHE_SUPPORTED: 0
      GLOBAL_MEMORY_BUS_WIDTH: 128
      GPU_OVERLAP: 1
      INTEGRATED: 0
      KERNEL_EXEC_TIMEOUT: 1
      L2_CACHE_SIZE: 2097152
      LOCAL_L1_CACHE_SUPPORTED: 1
      MANAGED_MEMORY: 1
      MAXIMUM_SURFACE1D_LAYERED_LAYERS: 2048
      MAXIMUM_SURFACE1D_LAYERED_WIDTH: 16384
      MAXIMUM_SURFACE1D_WIDTH: 16384
      MAXIMUM_SURFACE2D_HEIGHT: 65536
      MAXIMUM_SURFACE2D_LAYERED_HEIGHT: 16384
      MAXIMUM_SURFACE2D_LAYERED_LAYERS: 2048
      MAXIMUM_SURFACE2D_LAYERED_WIDTH: 16384
      MAXIMUM_SURFACE2D_WIDTH: 65536
      MAXIMUM_SURFACE3D_DEPTH: 4096
      MAXIMUM_SURFACE3D_HEIGHT: 4096
      MAXIMUM_SURFACE3D_WIDTH: 4096
      MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS: 2046
      MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH: 16384
      MAXIMUM_SURFACECUBEMAP_WIDTH: 16384
      MAXIMUM_TEXTURE1D_LAYERED_LAYERS: 2048
      MAXIMUM_TEXTURE1D_LAYERED_WIDTH: 16384
      MAXIMUM_TEXTURE1D_LINEAR_WIDTH: 134217728
      MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH: 16384
      MAXIMUM_TEXTURE1D_WIDTH: 65536
      MAXIMUM_TEXTURE2D_ARRAY_HEIGHT: 16384
      MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES: 2048
      MAXIMUM_TEXTURE2D_ARRAY_WIDTH: 16384
      MAXIMUM_TEXTURE2D_GATHER_HEIGHT: 16384
      MAXIMUM_TEXTURE2D_GATHER_WIDTH: 16384
      MAXIMUM_TEXTURE2D_HEIGHT: 65536
      MAXIMUM_TEXTURE2D_LINEAR_HEIGHT: 65536
      MAXIMUM_TEXTURE2D_LINEAR_PITCH: 1048544
      MAXIMUM_TEXTURE2D_LINEAR_WIDTH: 65536
      MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT: 16384
      MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH: 16384
      MAXIMUM_TEXTURE2D_WIDTH: 65536
      MAXIMUM_TEXTURE3D_DEPTH: 4096
      MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE: 16384
      MAXIMUM_TEXTURE3D_HEIGHT: 4096
      MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE: 2048
      MAXIMUM_TEXTURE3D_WIDTH: 4096
      MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE: 2048
      MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS: 2046
      MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH: 16384
      MAXIMUM_TEXTURECUBEMAP_WIDTH: 16384
      MAX_BLOCK_DIM_X: 1024
      MAX_BLOCK_DIM_Y: 1024
      MAX_BLOCK_DIM_Z: 64
      MAX_GRID_DIM_X: 2147483647
      MAX_GRID_DIM_Y: 65535
      MAX_GRID_DIM_Z: 65535
      MAX_PITCH: 2147483647
      MAX_REGISTERS_PER_BLOCK: 65536
      MAX_REGISTERS_PER_MULTIPROCESSOR: 65536
      MAX_SHARED_MEMORY_PER_BLOCK: 49152
      MAX_SHARED_MEMORY_PER_MULTIPROCESSOR: 65536
      MAX_THREADS_PER_BLOCK: 1024
      MAX_THREADS_PER_MULTIPROCESSOR: 2048
      MEMORY_CLOCK_RATE: 1001000
      MULTI_GPU_BOARD: 0
      MULTI_GPU_BOARD_GROUP_ID: 0
      PCI_BUS_ID: 1
      PCI_DEVICE_ID: 0
      PCI_DOMAIN_ID: 0
      STREAM_PRIORITIES_SUPPORTED: 1
      SURFACE_ALIGNMENT: 512
      TCC_DRIVER: 0
      TEXTURE_ALIGNMENT: 512
      TEXTURE_PITCH_ALIGNMENT: 32
      TOTAL_CONSTANT_MEMORY: 65536
      UNIFIED_ADDRESSING: 1
      WARP_SIZE: 32


<br>

## 3. Sum

GPU는 Code 최적화에 따라서 연산 시간에 많은 차이를 보인다. 간단한 SUM Code 조차도 CUDA에서 최적화 하는 것이 쉽지 않은 일이다([GPU_SUM.pdf](/assets/data/Numba_Cuda/gpu_sum_reduction.pdf)). 하지만 Numba의 reduce를 이용하면 SUM을 CUDA로 쉽게 Coding 할 수 있다.

<br>

### 3.1. Sum Kernel Code using reduce of numba


```python
from numba import cuda
from numba.cuda import to_device
import numpy as np

@cuda.reduce
def sum_reduce(a, b):
    return a + b
```

<br>

### 3.2. Sum Host Code using reduce of numba


```python
import math
import numpy as np
from numpy import float32
from numpy.random_intel import standard_normal

n_sample = 2 ** 27 - 157

data = float32(standard_normal(n_sample))
d_data = to_device(data.copy())

with Timer('Sum By CPU'):
    sum_cpu = np.sum(data)

_ = sum_reduce(data)
    
with Timer('Sum By GPU'):
    sum_gpu = sum_reduce(d_data)
    
print(f'CPU Result: {sum_cpu}')
print(f'GPU Result: {sum_gpu}')
```

    Sum By CPU ==> Elapsed time: 0.21539920 sec
    Sum By GPU ==> Elapsed time: 0.02144496 sec
    CPU Result: 2670.03662109375
    GPU Result: 2670.000244140625


<br>

### 3.3. Sum Code using reduction

[GPU_SUM.pdf](/assets/data/Numba_Cuda/gpu_sum_reduction.pdf)의 예제를 Numba에서도 구현 해 볼 수 있다. 아래 Sum_kernel을 한번만 호출하고 남은 연산을 CPU에서 처리 하여도 GPU를 활용하는 것이 더 효율적임을 볼 수 있다.


```python
# Kernel Code
from numba import cuda
from numba.cuda import to_device
import numpy as np

@cuda.jit("void(float32[:], float32[:], int64)")
def sum_kernel(out, data, n):
    tid = cuda.threadIdx.x
    idx = cuda.grid(1)
    idx_block_start = cuda.blockIdx.x * cuda.blockDim.x

    if idx >= n:
        return

    stride = cuda.blockDim.x // 2

    while stride > 0:
        if tid < stride and (idx_block_start + tid + stride) < n:
            data[idx_block_start + tid] += data[idx_block_start + tid + stride]
        cuda.syncthreads()
        stride //= 2

    if (tid == 0):
        out[cuda.blockIdx.x] = data[idx_block_start]

# Host Code
import math
import numpy as np
from numpy import float32
from numpy.random_intel import standard_normal

n_sample = 2 ** 27 - 157

data = float32(standard_normal(n_sample))
d_data = to_device(data.copy())

with Timer('Sum By CPU'):
    sum_cpu = np.sum(data)

threadsperblock = 128
blockspergrid = math.ceil(n_sample / threadsperblock)
out_of_gpu = cuda.device_array(blockspergrid, float32)

sum_kernel[blockspergrid, threadsperblock](out_of_gpu, data, n_sample) # For Compile

with Timer('Sum By GPU'):
    sum_kernel[blockspergrid, threadsperblock](out_of_gpu, d_data, n_sample)
    out_from_gpu = out_of_gpu.copy_to_host()
    sum_gpu = np.sum(out_from_gpu)

print(f'CPU Result: {sum_cpu}')
print(f'GPU Result: {sum_gpu}')
```

    Sum By CPU ==> Elapsed time: 0.21521380 sec
    Sum By GPU ==> Elapsed time: 0.08513450 sec
    CPU Result: -6470.31591796875
    GPU Result: -6470.2724609375


<br>

## 4. 참고자료
[1] Dr. Brian Tuomanen. (2018). Chapter3, Hands-On GPU Programming with Python and CUDA (39).


```python

```